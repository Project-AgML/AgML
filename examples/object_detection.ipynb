{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as tra\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.transforms import functional as F\n",
    "import albumentations as A\n",
    "\n",
    "import agml\n",
    "import agml.train.utils\n",
    "from agml.train.engine import train_one_epoch, evaluate, validate\n",
    "from agml.train.datatools import COCOObjectDetectionDataset, get_box_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agml.data.syntheticdata import HeliosDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir ../agml/Helios\n",
    "# !git clone https://github.com/PlantSimulationLab/Helios.git ../agml/Helios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/amoghjoshi/Documents/Amogh/Programs/Python/AgData/agml/Helios/plugins/canopygenerator/include/CanopyGenerator.h'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/gd/gbtgxj8112g_t063hk5jmvb00000gn/T/ipykernel_56116/1814262297.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mhdg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mHeliosDataGenerator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/Amogh/Programs/Python/AgData/agml/data/syntheticdata.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, path_helios_dir)\u001B[0m\n\u001B[1;32m     29\u001B[0m         self.path_main_cpp = os.path.join(\n\u001B[1;32m     30\u001B[0m             os.path.dirname(os.path.dirname(__file__)), '_helios/main.cpp')\n\u001B[0;32m---> 31\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcanopy_types\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_canopy_types\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     32\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcanopy_params\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_canopy_params\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcanopy_param_ranges\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_initial_canopy_param_ranges\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Amogh/Programs/Python/AgData/agml/data/syntheticdata.py\u001B[0m in \u001B[0;36mget_canopy_types\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m         \u001B[0;31m# Read CanopyGenerator.h to define potential canopy types\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 45\u001B[0;31m         \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath_canopygen_header\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     46\u001B[0m             \u001B[0mcanopygen_header_txt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadlines\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/amoghjoshi/Documents/Amogh/Programs/Python/AgData/agml/Helios/plugins/canopygenerator/include/CanopyGenerator.h'"
     ]
    }
   ],
   "source": [
    "hdg = HeliosDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdg.canopy_param_ranges['VSPGrapevine']['grape_subdivisions'] = [[4.0, 4.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdg.generate_data(n_imgs=1, canopy_type='VSPGrapevine', simulation_type='rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define the number of class\n",
    "num_classes=2 #background and grape\n",
    "# load an instance segmentation model pre-trained pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataset Object and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "\n",
    "# the dataset object\n",
    "img_path=\"./images\"\n",
    "json_path=\"./trainval_detection.json\"\n",
    "\n",
    "from datatools import COCOObjectDetectionDataset, get_box_transform\n",
    "\n",
    "\n",
    "#you can add your own albumentations transforms here \n",
    "\n",
    "transform_list = A.Compose([\n",
    "        #A.Resize(200, 300),\n",
    "        #A.CenterCrop(100, 100),\n",
    "        #A.RandomCrop(80, 80),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Rotate(limit=(-6, 6), p=0.6),\n",
    "        #A.ShiftScaleRotate(rotate_limit=50, p=0.6)\n",
    "        #A.SmallestMaxSize(max_size=1292, p=1)\n",
    "        #A.augmentations.transforms.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.15, rotate_limit=5, p=0.5)\n",
    "        A.RandomScale(scale_limit=0.2, p=0.5)\n",
    "        #A.core.composition.OneOf([A.Resize(2298, 1292, interpolation=1, always_apply=False, p=1), A.Resize(3109, 1748, interpolation=1, always_apply=False, p=1), A.Resize(2568, 1444, interpolation=1, always_apply=False, p=1), A.Resize(2839, 1596, interpolation=1, always_apply=False, p=1)],p=0.5)\n",
    "        #A.augmentations.transforms.Resize(2298, 1292, interpolation=1, always_apply=False, p=1)\n",
    "        #A.VerticalFlip(p=0.5),\n",
    "        #A.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "\n",
    "trainval = COCOObjectDetectionDataset(root = img_path,json_dir = json_path, transforms=transform_list, train=True)\n",
    "\n",
    "\n",
    "# trainval = dset.CocoDetection(root = img_path,annFile = json_path)#dataset_test = GrapeBunchDataset('test', get_transform(train=False))\n",
    "\n",
    "train, val = torch.utils.data.random_split(trainval, [2, 1]) # put 2 images in train and 1 in val for this dummy example\n",
    "\n",
    "\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(train, batch_size=1, shuffle=True, num_workers=0, collate_fn=utils.collate_fn)\n",
    "\n",
    "#data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=4, collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_validate = torch.utils.data.DataLoader(train, batch_size=1, shuffle=False, num_workers=0, collate_fn=utils.collate_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets train for 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now start the training process\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.009, momentum=0.9, weight_decay=0.0006)\n",
    "\n",
    "# and a learning rate scheduler (optional)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=1)  # optional lr scheudler (gamma is 1 by default which means no scheduling)\n",
    "\n",
    "# let's train it for 50 epochs and save after best epoch\n",
    "num_epochs = 50\n",
    "\n",
    "best_val_loss=999\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=2)\n",
    "    # update the learning rate (optional)\n",
    "    lr_scheduler.step()\n",
    "    # evaluate and checkpoint using the validate dataset\n",
    "    best_val_loss=validate(model, data_loader_validate, device=device, best_val_loss=best_val_loss)\n",
    "\n",
    "\n",
    "print('Trained for '+str(num_epochs) + ' epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}